# AI-Knowledge-Base

## LLMs

### Local LLMs

- [**Ollama**](/local-llm/README.md)
- [**llama.cpp**](/local-llm/README.md)
- [**NVIDIA NIM (NVIDIA Inference Microservices)**](/local-llm/README.md)

### Core techniques (prompt engineering)

- **Chain-of-Thought and Tool Use** - Systematic step-by-step techniques for better outputs with function calling

- [RAG + Summarization (Documentation System): Ollama, LangChain, Qdrant](/rag-pipeline/README.md)

### Agent Systems

- **AI Agent (LangGraph) and MCP Server** - Intelligent agent with MCP server and memory management

- **Orchestration** - Multi-agent systems, complex workflows, state management and Human-in-the-loop

### Model Customization

- **LLM PEFT (Parameter-Efficient Fine-Tuning)** - LLM [fine-tuning and reinforcement learning](https://unsloth.ai/docs/get-started/fine-tuning-llms-guide) with [Unsloth](https://unsloth.ai/docs)

- **Custom Quantization with [llama.cpp](https://github.com/ggml-org/llama.cpp)** - Convert and quantize a model

### Model Evaluation

- **Model Evaluation & Benchmarking** - lm-eval and RAGAS

## Machine Learning

### Neural Network

- **NVIDIA cuDNN (CUDA Deep Neural Network): PyTorch and TensorFlow with GPU support**

### Deep Neural Network
